#  Prueba Tecnica

##  Descripci贸n
Este desarrollo realiza el procesamiento de datos para la API de lanzamientos espaciales, su arquitectura esta basada en un motor de procesamiento Apache Spark, el orquestador de pipelines por Apache Airflow y un almacenamiento en Delta Lake. 

##  Descripcion de Caracter铆sticas
**Apache Spark:** es un motor de procesamiento de datos de c贸digo abierto dise帽ado para manejar grandes vol煤menes de informaci贸n de manera distribuida y eficiente. Es ampliamente utilizado en el an谩lisis de datos, aprendizaje autom谩tico y procesamiento de datos en tiempo real. Sus principales caracter铆sticas incluyen:
    - Procesamiento en memoria para mayor velocidad.
    - Soporte para m煤ltiples lenguajes como Python, Scala y Java.
    - Integraci贸n con diversas fuentes de datos, como HDFS, S3, Cassandra y MongoDB.
    - Compatible con procesamiento en lotes y en tiempo real mediante Spark Streaming.

**Apache Airflow:** es una plataforma de orquestaci贸n de flujos de trabajo que permite la programaci贸n, ejecuci贸n y monitoreo de tareas complejas en procesos de datos. Es ampliamente utilizado en la gesti贸n de ETLs, pipelines de datos y automatizaci贸n de procesos empresariales. Sus principales caracter铆sticas incluyen:
    - Definici贸n de flujos de trabajo mediante c贸digo en Python.
    - Planificaci贸n y ejecuci贸n programada de tareas.
    - Integraci贸n con m煤ltiples herramientas y servicios en la nube.
    - Visualizaci贸n de la ejecuci贸n de flujos de trabajo mediante su interfaz web.
    - Manejo de dependencias entre tareas de forma flexible.

**Delta Lake** es una capa de almacenamiento open-source que mejora la confiabilidad y el rendimiento de los datos almacenados en formato **Parquet**, proporcionando transacciones ACID, versionado de datos y manejo eficiente de esquemas. 

**Databricks** implementa Delta Lake bajo un enfoque de **Esquema Medallion**, que organiza los datos en tres capas:
- **Bronze Layer:** Contiene los datos crudos tal como fueron ingeridos desde las fuentes, sin transformaciones. Sirve como respaldo en caso de errores en el procesamiento.
- **Silver Layer:** Contiene datos limpios y procesados, con una estructura m谩s organizada y enriquecida. Aqu铆 se eliminan duplicados y se aplican reglas de calidad de datos.
- **Gold Layer:** Es la capa de datos altamente optimizados y listos para an谩lisis y consumo en reportes y modelos de machine learning. Generalmente, los datos en esta capa est谩n agregados y optimizados para rendimiento.

El uso del esquema **Medallion** permite una trazabilidad clara del linaje de datos, facilitando la gobernanza y el versionado de datos dentro de **Databricks**.


##  Instalaci贸n
### Requisitos previos
Aseg煤rate de tener instalado:
- **Docker**(4.38.0)
- **VisualStudioCode** (>= 1.98.0)
- **Github**

### Clonar el repositorio
```bash
git clone https://github.com/tu-repo.git
cd tu-repo
```

### Configuraci贸n del Backend (FastAPI)
1. Crear un entorno virtual:
```bash
python -m venv env
source env/bin/activate  # Linux/macOS
env\Scripts\activate  # Windows
```
Despliegue con Docker
Para ejecutar la aplicaci贸n con Docker Compose:
```bash
docker-compose up --build
```

###  Despliegue de Im谩genes de Docker en el Ambiente
Para desplegar las im谩genes de Docker dentro del ambiente, sigue estos pasos:

1. **Construir las im谩genes de Docker**
```bash
docker-compose build
```

2. **Verificar que las im谩genes han sido creadas**
```bash
docker images
```

3. **Etiquetar y subir las im谩genes a un registro de contenedores (opcional)**
Si deseas almacenar las im谩genes en un **Docker Registry** como Docker Hub o Azure Container Registry:
```bash
docker tag nombre-imagen usuario/nombre-imagen:latest
docker push usuario/nombre-imagen:latest
```

4. **Levantar los contenedores en el servidor de producci贸n**
```bash
docker-compose up -d
```

5. **Verificar que los contenedores est谩n en ejecuci贸n**
```bash
docker ps
```

6. **Acceder a los logs en caso de errores**
```bash
docker logs -f nombre-contenedor
```

7. **Detener y eliminar los contenedores si es necesario**
```bash
docker-compose down
```

##  Ejecuci贸n con Docker
Para ejecutar la aplicaci贸n con Docker Compose:
```bash
docker-compose up --build
```
